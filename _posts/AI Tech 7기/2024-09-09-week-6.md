---
title: AI Tech 6주차 학습정리
categories: ['Retrospect']
tags: []
image: /assets/img/previews/resized/ai_tech.png
math: true
---

## 1. Python Darts Package
---

Python의 Darts 패키지는 시계열 예측을 위한 모델들을 모아둔 패키지이다. 
기본적으로 아래와 같이 예측하고자할 시계열 데이터인 TimeSeries 객체와 모델을 생성한 뒤, fit-predict하면 된다.

~~~python
import pandas as pd
from darts import TimeSeries
from darts.model import ExponentialSmoothing

df = pd.read_csv('ohlc.csv')
series = TimeSeries.from_dataframe(df, 'datetime', 'close')
model = ExponentialSmoothing()
model.fit(series)
prediction = model.predict(n=100)
~~~

fit 및 predict할 때 past_covariates 매개변수를 통해 예측을 도와주는 또다른 시계열 데이터를 추가할 수도 있다.

<br/>

## 2. Oversampling and Undersampling
---

테스트 데이터의 target label이 불균형하게 분포되어있다면 학습하는데에 있어서 다양한 문제들이 발생할 수 있다.
이를 방지하기 위해 target의 분포를 균등하게 조정하는 방법론이 oversampling과 undersampling이다.

Undersampling은 다수 클래스의 데이터를 줄여 소수 클래스의 비율에 맞추는 방법이다. 
이의 단점은 다수 클래스의 데이터를 삭제하는 과정에서 유의미한 정보의 손실이 발생할 수 있다는 점이다.

반대로 Oversampling은 소수 클래스의 데이터를 늘려 다수 클래스의 비율에 맞추는 방법이다.
정보의 손실이 일어나지 않는다는 점이 장점이지만, 소수 클래스를 임의로 늘림으로써 과적합이 발생할 수 있으며, 노이즈나 이상치에 민감하다는 단점이 존재한다.

<br/>

## 3. 결측치 처리
---

먼저 결측치를 데이터의 대표값을 대체하는 방법이 있다.
열의 평균값이나 중간값, 또는 최빈값으로 대체할 수 있다.

나아가 결측치를 모델의 예측값으로 대체하는 방법이 있는데 MICE(Multivariate Imputation by Chained Equations)가 대표적이다.

MICE는 우선 열별로 결측치를 예측하여 모든 결측치를 채운다. 모든 열의 결측치를 채우고 나면, 이를 예측값이 어느정도 수렴할 때까지 반복해서 수행한다.

<br/>

## 4. UltraGCN
---

LightGCN을 발전시킨 모델인 UltraGCN에 대한 리뷰이다.

<https://joshua5301.github.io/posts/ultra-gcn/>



