---
title: AI Tech 8주차 학습정리
categories: ['Retrospect']
tags: []
image: /assets/img/previews/resized/ai_tech.png
math: true
---

## 1. Neural Collaborative Filtering
---

'Neural Collaborative Filtering' 논문을 리뷰하였다.

<https://joshua5301.github.io/posts/neural-collaborative-filtering/>

<br>

## 2. Deep & Wide
---

'Wide & Deep Learning for Recommender Systems' 논문을 리뷰하였다.

<https://joshua5301.github.io/posts/wide-and-deep/>

<br>

## 3. Clustering
---

### 3.1 K-means Clustering

K-means Clustering은 가장 대표적인 클러스터링 알고리즘으로, 데이터 포인트를 K개의 클러스터로 묶는다. 이의 과정은 아래와 같다.

1. 데이터 포인트 중 랜덤하게 K개의 중심을 선택한다.
2. 각 데이터 포인트를 가장 가까운 중심에 할당한다.
3. 각 클러스터의 중심을 클러스터에 속한 데이터 포인트들의 평균으로 업데이트한다.
4. 중심이 변하지 않을 때까지 2, 3을 반복한다.

장점: 거리에 기반하기에 간단하고 직관적이다.
대용량 데이터에도 빠른 적용이 가능하다.

단점: 초기 중심 선택에 민감하다. (k-means++로 초기화 문제를 어느정도 완화할 수 있다.)
클러스터의 개수 K를 미리 정해야 한다. (Elbow Method로 적절한 k를 찾을 수 있다.)
Outlier에 민감하다.

### 3.2 DBSCAN

DBSCAN은 Density-Based Spatial Clustering of Applications with Noise의 약자로 데이터의 밀도를 기반으로 클러스터를 구성한다. 이의 과정은 아래와 같다.

1. 임의의 데이터 포인트를 선택한다.
2. 이 데이터 포인트에서 반경 $\epsilon$ 내에 데이터 포인트가 $n$개 이상 있으면 이 데이터 포인트를 core point로 지정하고 이를 중심으로 클러스터를 형성한다.
3. core point를 제외한 클러스터 내의 다른 점들도 2의 과정을 진행한다. 이 때 다른 점도 core point가 되면 하나의 클러스터로 합친다.
4. 2, 3을 반복하여 모든 데이터 포인트를 검사한다.

장점: 클러스터의 개수를 미리 정하지 않아도 된다.
이상치에 덜 민감하다.

단점: 하이퍼파라미터 $\epsilon$과 $n$을 설정해야 한다.
고차원 데이터에서는 잘 작동하지 않는다.