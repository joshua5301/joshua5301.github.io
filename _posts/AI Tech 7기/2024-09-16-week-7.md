---
title: AI Tech 7주차 학습정리
categories: ['Retrospect']
tags: []
image: /assets/img/previews/resized/ai_tech.png
math: true
---

## 1. 문제 배경
---

level1의 마지막 프로젝트로 비트코인 가격 예측을 진행하였다.
주어진 문제는 multi-class classification으로, -0.5% 이하로 하락했으면 0, -0.5% ~ 0%로 하락했으면 1, 0% ~ 0.5%로 상승했으면 2, 0.5% 이상 상승했으면 3으로 분류해야한다.

하지만 이를 있는 그대로 classification 문제로 받아들이게 된다면 문제점이 하나 생긴다.
실수 범위의 등락 퍼센트를 binning하여 단순히 4개의 class로 변환하는 과정에서 정보의 손실이 불가피하게 발생한다는 점이다.
구체적인 예시로, 0.4% 상승과 0.1% 상승을 비교해보자.
둘 다 0% ~ 0.5%에 해당하므로 class 2에 속하지만, 각각 class 1과 class 3에 가깝다는 점이 다르다.
하지만 classification에서는 이러한 세부 정보가 소실되고 모델은 데이터의 class가 2라는 점밖에 모른다.

이 단점을 극복하고자 등락 퍼센트를 직접 예측하는 regression 문제로 변환해 접근해볼 수 있을 것이다.
하지만 이 역시도 단점이 존재하는데, regression은 class의 경계에 집중하지 못하고 정확한 가격을 굳이 맞추려 한다는 것이다.
다시 말해, regression은 classification으로 인해 소실된 정보에 오히려 너무 불필요하게 집중한다.

결국, classification과 regression 사이 어딘가에 존재하는 모델의 필요성이 대두된다.

<br/>

## 2. 가설 제안
---

이에 data의 label을 smoothing하는 soft-labeling 방법을 제안한다.
soft-labeling이란, label를 각각의 class에 대한 확률로 두어 각 데이터들의 label 분포를 부드럽게 하는 것이다.
예를 들어, +0.4%는 class 2일 확률이 0.6, class 3일 확률이 0.4로 둘 수 있고, +0.1%은 class 1일 확률이 0.4, class 2일 확률이 0.6으로 둘 수 있다. 이렇게 두면 정보의 손실을 어느정도 완화하는 동시에 모델이 class의 경계에 집중할 수 있도록 한다.

soft-labeling의 적용을 정당화하기 위해 문제를 단순화하여 모델이 오직 class 1과 class 2, 즉 오를지 내릴지만 예측하도록 하자.
그렇다면 soft-labeling을 아래와 같이 tanh함수로 구현할 수 있다. 

$$
label = tanh(s \times (price\;change\;percentage))
$$

이때 s는 label의 smoothness를 결정하는 hyperparameter로, s가 커지면 문제가 classification에 가까워지고 작아지면 문제가 regression에 가까워진다. tanh 함수의 그래프를 생각해보면 쉽게 알 수 있다. s가 매우 크다면 그래프가 좌우로 압축되어 price change percentage가 0에서 조금만 벗어나도 바로 label이 -1이나 1에 근사하는 값이 된다. 반대로 s가 작다면 label은 price change percentage를 단순히 scaling한 값이 된다. tanh 함수는 0 근처에서 y = x와 근사하기 때문이다.

적절한 smoothness를 통해 계산된 label을 모델이 예측하도록 하면 최적의 label 표현이 되어 모델의 성능을 최대화시킬 수 있을 것이다.

<br/>

## 3. 실험 결과
---

비교대상이 되는 baseline model은 가격의 변동을 label로 하는 단순한 regression model이다.
우리가 관심있어하는 label-smoothing을 적용한 model은 tanh 함수를 통해 변환된 값을 label로 두는 regression model이다.
두 모델 모두 단일 lightGBM 모델이며, hyperparameter는 아래와 같이 두었다.

||learning_rate|num_leaves|lambda_l1|lambda_l2|max_depth|extra_trees|path_smooth|
|value|0.1|10|0.5|0.5|4|True|0.5|

baseline model의 accuracy는 0.5258가 나왔다.
이는 shuffle하지 않은 k=4인 k-fold validation의 결과로 하였다.

나아가 아래는 smoothness에 따른 label-smoothing을 적용한 model의 accuracy이다.
이 역시 accuracy를 shuffle하지 않은 k=4인 k-fold validation을 통해 구하였으며, smoothness를 0.1 단위로 증가시켜 50까지 탐색해보았다.

![accuracy_graph](/assets/img/contents/week-7/accuracy_graph.png){: width="500px"}

그래프로부터 알 수 있는 사실은, accuracy가 대략 7부근까지는 급격하게 상승하지만, 이후로는 0.550과 0.555 사이를 유지한다는 점이다.
smoothness를 극단적으로 크게 만들어도 이 부근을 유지하였다.
이는 최소한 현재 풀고 있는 문제는 classification으로 인해 손실되는 정보가 그리 중요하지 않고 class의 경계에 집중하는 것이 더 중요하다라는 것을 나타낸다. 실제로 팀 내의 시도도 regression보다 classification의 접근 방식이 성능이 훨씬 좋게 나왔다.


