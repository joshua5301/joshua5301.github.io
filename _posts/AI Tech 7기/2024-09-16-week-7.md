---
title: AI Tech 7주차 학습정리
categories: ['Retrospect']
tags: []
image: /assets/img/previews/resized/ai_tech.png
math: true
---

## 1. 비트코인 등락 예측 
---

level1의 마지막 프로젝트로 비트코인 가격 예측을 진행하였다.
주어진 문제는 multi-class classification으로, -0.5% 이하로 하락했으면 0, -0.5% ~ 0%로 하락했으면 1, 0% ~ 0.5%로 상승했으면 2, 0.5% 이상 상승했으면 3으로 분류해야한다.

하지만 이를 있는 그대로 classification 문제로 받아드리게 된다면 문제점이 하나 생긴다.
실수 범위의 등락 퍼센트를 binning하여 단순히 4개의 class로 변환하는 과정에서 정보의 손실이 불가피하게 발생한다는 점이다.
구체적인 예시로, 0.4% 상승과 0.1% 상승을 비교해보자.
둘 다 0% ~ 0.5%에 해당하므로 class 2에 속하지만, 각각 class 1과 class 3에 가깝다는 점이 다르다.
하지만 classification에서는 이러한 세부 정보가 소실되고 모델은 데이터의 class가 2라는 점밖에 모른다.

이 단점을 극복하고자 등락 퍼센트를 직접 예측하는 regression 문제로 변환해 접근해볼 수 있을 것이다.
하지만 이 역시도 단점이 존재하는데, regression은 class의 경계에 집중하지 못하고 정확한 가격을 굳이 맞추려 한다는 것이다.
다른 말로, regression은 classification으로 인해 소실된 정보에 오히려 너무 불필요하게 집중한다.

결국, classification과 regression 사이 어딘가에 존재하는 모델의 필요성이 대두된다.
이에 data의 label을 smoothing하는 soft-labeling을 제안한다.
soft-labeling이란, label를 각각의 class에 대한 확률로 두어 각 데이터들의 label 분포를 부드럽게 하는 것이다.
예를 들어, +0.4%는 class 2일 확률이 0.6, class 3일 확률이 0.4로 둘 수 있고, +0.1%은 class 1일 확률이 0.4, class 2일 확률이 0.6으로 둘 수 있다. 이렇게 두면 모델이 class의 경계에 집중하면서 필요한 정보를 남길 수 있다.

soft-labeling의 적용을 정당화하기 위해 문제를 단순화하여 class를 오직 1과 2, 즉 오를지 내릴지만 예측하도록 하자.
그렇다면 soft-labeling을 아래와 같이 tanh함수로 구현할 수 있다.

이때 s는 labeling smoothness로, hyperparameter이다. hyperparameter s가 커지면
