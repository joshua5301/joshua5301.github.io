---
title: AI Tech 5주차 학습정리
categories: ['Retrospect']
tags: []
image: /assets/img/previews/resized/ai_tech.png
math: true
---

## 1. LightGCN Implementation
---

LightGCN 구현을 드디어 완료하였다.

<https://github.com/joshua5301/lightgcn>

이전 데이콘 모의 대회 데이터에 적용시켜보았는데 public 14등이라는 애매한 등수를 받았다. 그래도 오직 collaborative filtering만 이용한 것치고는 나쁘지 않은 등수라 생각한다.

<https://dacon.io/competitions/official/236290/leaderboard>

<br/>

## 2. NDCG
---

먼저, Relevance는 유저와 아이템이 얼마나 관련되었는지(좋아하는지)를 나타내는 지표이다. 예를 들어, 유저 A가 스타워즈를 매우 좋아하고 토이스토리를 그럭저럭 좋아한다면 relevance를 각각 2과 1로 둘 수 있다.

Cumulative Gain은 예측한 아이템의 실제 relevance의 합으로 계산된다. 따라서 CG가 높으면 예측한 아이템들이 유저와 관련이 높다는 것을 의미한다.

$$
CG_p = \sum_{i=1}^{p} rel_i
$$

Cumulative Gain의 단점은 예측한 아이템들의 순서(순위)를 고려하지 못한다는 점이다. 예를 들어, 모델이 토이스토리를 스타워즈보다 더 관련성이 높다고 예측하든, 스타워즈가 토이스토리보다 더 관련성 높다고 예측하든 두 예측 모두 똑같은 점수를 받는다.

이러한 단점을 보완하기 위해 예측한 아이템들의 순서(순위)에 따라 가중치를 부여한게 Discounted Cumulative Gain이다.

$$
DCG_p = \sum_{i=1}^{p} \frac{rel_i}{log_2(1 + i)}
$$

보다시피 relevance에 $1 / log_2(1 + i)$의 가중치를 두어 모델이 가장 관련성이 높다고 예측한 아이템의 relevance가 높게 평가되도록 하였다.

마지막으로 DCG를 0과 1사이에 오도록 normalize한 것이 바로 nDCG이다. 

$$
nDCG_p = \frac{DCG_p}{IDCG_p}
$$

여기서 IDCG는 Ideal한 DCG로, 모델이 예측하여 받을 수 있는 가장 높은 DCG이다.

<br/>

## 3. Rejection Sampling
---

Normalizing constant를 모르는 확률 분포에서 샘플링하고 싶다고 하자. 즉, 아래 식에서 실제 분포 $p(z)$는 모르고 $\tilde{p}(z)$만 아는 것이다. rejection sampling을 사용하면 실제 분포를 정확히 몰라도 이로부터 샘플링할 수 있게 된다.

$$
p(z) = \frac{\tilde{p}(z)}{Z_p} 
$$

Rejection sampling의 과정은 아래와 같다.
1. 모든 z에 대해 $kq(z) \le \tilde{p}(z)$인 확률분포 $q(z)$를 임의로 잡는다. 
2. 확률분포 $q(z)$에서 샘플링하여 $z_0$를 얻는다.
3. $[0, kq(z_0)]$의 균등분포에서 샘플링하여 $u_0$를 얻는다.
4. $u_0 \lt \tilde{p}(z_0)$라면 $z_0$ 샘플을 accept하고 그렇지 않다면 샘플을 reject한다.

<br/>

## 4. Data Attribution and Influence Function
---

Data attribution은 training data point마다 각각 가치, 혹은 영향을 측정하는 방식이다. Influence function은 이의 한 방법으로, 특정 train data point가 test loss에 얼마나 어떻게 영향 주는지 측정한다.

먼저 특정 데이터 포인트의 loss를 $\epsilon$만큼 가중한다고 하자. 이 때 최적의 parameter는 아래와 같고 이를 $\hat{\theta}_{\epsilon, z}$ 라 하자.

$$
\hat{\theta}_{\epsilon, z} = \underset{\theta}{argmin} \frac{1}{n} \sum_{i=1}^n L(z_i, \theta) + \epsilon L(z, \theta)
$$

그렇다면 influence function은 아래와 같이 정의된다.

$$
I_{up, loss}(z, z_{test}) = \frac{dL(z_{test}, \hat{\theta}_{\epsilon, z})}{d \epsilon}\bigg\rvert_{\epsilon = 0}
$$

예를 들어, influence function이 양수면 $\epsilon$이 증가할수록 test loss가 커진다는 것이기에 그 data가 정확한 예측을 방해하는 data임을 의미한다.

